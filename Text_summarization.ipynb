{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ABSTRACTIVE TEXT SUMMARIZATION USING GOOGLE PEGASUS -\n",
        " X SUM AND LARGE MODELS by *MAVERICK_GR **\n",
        "\n",
        "Since students find it extremely difficult to understand and memorize technical concepts explained over many sentences, developed abstractive text summarization models to explain the concepts in a concise manner at the same time making sure that meaning of the sentences is not lost. "
      ],
      "metadata": {
        "id": "cUTTrQ0IKmsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT7qmi02gb_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9ba9a4-d3f5-4b2b-e864-c789156f3172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing........20%\n",
            "Installing........40%\n",
            "Installing........60%\n",
            "Installing........80%\n",
            "Install and importing done\n"
          ]
        }
      ],
      "source": [
        "!pip install torch --quiet\n",
        "print('Installing........20%')\n",
        "!pip install torchvision --quiet\n",
        "print('Installing........40%')\n",
        "!pip install torchaudio --quiet\n",
        "print('Installing........60%')\n",
        "!pip install transformers --quiet\n",
        "print('Installing........80%')\n",
        "!pip install tk --quiet\n",
        "print('Install and importing done')\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def g_xsum(text):\n",
        "    tk_1 = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
        "    model_1 = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
        "    tokens = tk_1(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "    summary = model_1.generate(**tokens)\n",
        "    sum_1 = tk_1.decode(summary[0])\n",
        "    return(sum_1)"
      ],
      "metadata": {
        "id": "VEyG-anthG4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def g_large(text):\n",
        "    tk_2 = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
        "    model_2 = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-large\")\n",
        "    tokens = tk_2(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "    summary = model_2.generate(**tokens)\n",
        "    sum_2 = tk_2.decode(summary[0])\n",
        "    return(sum_2)"
      ],
      "metadata": {
        "id": "MpWxc6Mf0YtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Enter the text for summarization')\n",
        "text = input('::')\n",
        "print('_'*100)\n",
        "print('1. Brief summary')\n",
        "print('2. Elaborate summary')\n",
        "print('Make your choice')\n",
        "choice = int(input('Would you like a brief or elaborate summary :'))\n",
        "if choice == 1:\n",
        "  print('_'*100)\n",
        "  res_1 = g_xsum(text)\n",
        "  print('Brief summary of the text :')\n",
        "  print('_'*100)\n",
        "  print('Loading'+'*'*80)\n",
        "  print(res_1)\n",
        "elif choice == 2:\n",
        "  print('_'*100)\n",
        "  res_2 = g_large(text)\n",
        "  print('Elaborate summary of the text :')\n",
        "  print('_'*100)\n",
        "  print('Loading'+'*'*80)\n",
        "  print(res_2)\n",
        "else:\n",
        "  print('Invalid choice.... try again')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpEUzJyJ0Yw6",
        "outputId": "72ddb379-5551-4129-aca9-3aa4f077b9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text for summarization\n",
            "::transformer, device that transfers electric energy from one alternating-current circuit to one or more other circuits, either increasing (stepping up) or reducing (stepping down) the voltage. Transformers are employed for widely varying purposes; e.g., to reduce the voltage of conventional power circuits to operate low-voltage devices, such as doorbells and toy electric trains, and to raise the voltage from electric generators so that electric power can be transmitted over long distances.\n",
            "____________________________________________________________________________________________________\n",
            "1. Brief summary\n",
            "2. Elaborate summary\n",
            "Make your choice\n",
            "Would you like a brief or elaborate summary :2\n",
            "____________________________________________________________________________________________________\n",
            "Elaborate summary of the text :\n",
            "____________________________________________________________________________________________________\n",
            "Loading********************************************************************************\n",
            "<pad>Transformers are employed for widely varying purposes; e.g., to reduce the voltage of conventional power circuits to operate low-voltage devices, such as doorbells and toy electric trains, and to raise the voltage from electric generators so that electric power can be transmitted over long distances.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkOC95wilELo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopWDkamyZ6j"
      },
      "source": [
        "**Here i have tried abstractive text summarization using Pegasus XSum and Large. While, XSum is quite good in shrinking the large number of sentences into one/two meaningful sentences ( without losing the context ). pegasus-Large provides comprehensive summarization of the text going down to minute detail present in the text.** "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}